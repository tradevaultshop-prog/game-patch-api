import os
import json
import time
import random
import logging
import boto3
import requests
import yaml # <-- YENÄ° EKLENDÄ°
import scrapers # <-- YENÄ° EKLENDÄ° (scrapers.py dosyamÄ±z)
import concurrent.futures # <-- YENÄ° EKLENDÄ° (paralel iÅŸleme iÃ§in)
from datetime import datetime
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup
from utils import analyze_with_gemini 

load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

s3_client = boto3.client(
    "s3",
    endpoint_url=os.getenv("S3_ENDPOINT_URL"),
    aws_access_key_id=os.getenv("S3_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("S3_SECRET_ACCESS_KEY"),
    region_name="auto", 
)
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")

SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")

def send_alert(message):
    if not SLACK_WEBHOOK_URL:
        logging.warning("SLACK_WEBHOOK_URL tanÄ±mlÄ± deÄŸil. Bildirim atlanÄ±yor.")
        return
    try:
        payload = {"text": f"ðŸš¨ **GPNAI Cron Job HatasÄ±** ðŸš¨\n\n```{message}```"}
        requests.post(SLACK_WEBHOOK_URL, json=payload, timeout=5)
    except Exception as e:
        logging.error(f"Slack bildirimi gÃ¶nderilemedi: {e}")

if not GEMINI_API_KEY or not S3_BUCKET_NAME:
    error_msg = "âŒ .env dosyasÄ±nda GEMINI_API_KEY veya S3 bilgileri eksik!"
    send_alert(error_msg) 
    raise ValueError(error_msg)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("scraper.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

def create_session():
    session = requests.Session()
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
    session.mount("https://", HTTPAdapter(max_retries=retries))
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0 Safari/537.36"
    })
    return session

# --- ARTIK GEREKLÄ° DEÄžÄ°L ---
# TÃ¼m 'fetch_*' fonksiyonlarÄ± 'scrapers.py' dosyasÄ±na taÅŸÄ±ndÄ±.
# ---------------------------

def save_json_to_s3(data, base_name):
    filename = f"{base_name}_latest.json"
    try:
        json_string = json.dumps(data, indent=2, ensure_ascii=False)
        s3_client.put_object(
            Bucket=S3_BUCKET_NAME,
            Key=filename,
            Body=json_string,
            ContentType="application/json"
        )
        logging.info(f"âœ… JSON S3'e kaydedildi: {S3_BUCKET_NAME}/{filename}")
    except Exception as e:
        logging.error(f"âŒ S3'e yazma hatasÄ± ({filename}): {e}")
        send_alert(f"âŒ S3'e yazma hatasÄ± ({filename}): {e}")

# --- YENÄ° EKLENDÄ°: Paralel Veri Ã‡ekme Fonksiyonu ---
def fetch_game_data(game_config, session):
    """
    Bir oyunun verisini Ã§ekmek iÃ§in iÅŸ parÃ§acÄ±ÄŸÄ± (thread) tarafÄ±ndan Ã§alÄ±ÅŸtÄ±rÄ±lan fonksiyon.
    """
    game_name = game_config['game']
    fetch_function_name = game_config['fetch_function']
    
    try:
        logging.info(f"THREAD ðŸ”: {game_name} iÃ§in veri Ã§ekiliyor...")
        # 'scrapers.py' modÃ¼lÃ¼nden fonksiyonu ismine gÃ¶re bul ve Ã§alÄ±ÅŸtÄ±r
        fetch_function = getattr(scrapers, fetch_function_name)
        raw_data = fetch_function(session)
        return game_name, raw_data, game_config
    except Exception as e:
        logging.error(f"THREAD âŒ: {game_name} veri Ã§ekme hatasÄ±: {e}")
        return game_name, None, game_config
# ----------------------------------------------------

# --- GÃœNCELLENDÄ°: Ana Ã‡alÄ±ÅŸtÄ±rma BloÄŸu (Paralel + SÄ±ralÄ±) ---
if __name__ == "__main__":
    logging.info("ðŸš€ Faz 2: Paralel veri Ã§ekme ve sÄ±ralÄ± analiz baÅŸlatÄ±lÄ±yor...")
    
    try:
        # AdÄ±m 1: YapÄ±landÄ±rmayÄ± YÃ¼kle
        with open("sources.yaml", "r", encoding="utf-8") as f:
            games_config = yaml.safe_load(f)
        
        session = create_session()
        fetched_data = [] # (game_name, raw_data, config) listesi

        # AdÄ±m 2: Veri Ã‡ekme (Paralel)
        # ThreadPoolExecutor kullanarak tÃ¼m I/O (bekleme) iÅŸlemlerini aynÄ± anda yap
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(games_config)) as executor:
            # Her 'fetch_game_data' iÅŸlevine 'game_config' ve 'session'Ä± haritala
            futures = [executor.submit(fetch_game_data, config, session) for config in games_config]
            
            for future in concurrent.futures.as_completed(futures):
                fetched_data.append(future.result())

        logging.info(f"âœ… Paralel veri Ã§ekme tamamlandÄ±. {len(fetched_data)} oyun iÅŸlenecek.")
        session.close() # Session'Ä± artÄ±k kapatabiliriz.

        # AdÄ±m 3: Analiz ve Kaydetme (SÄ±ralÄ±)
        # Gemini API limitlerine takÄ±lmamak iÃ§in bu adÄ±mÄ± sÄ±rayla (tek tek) yapÄ±yoruz.
        for i, (game_name, raw_data, config) in enumerate(fetched_data):
            
            safe_name = config['safe_name']

            if not raw_data:
                fallback = f"{game_name} received balance changes and new content."
                logging.warning(f"âš ï¸  {game_name} iÃ§in veri yok. Fallback metin kullanÄ±lÄ±yor.")
                raw_data = fallback
            else:
                logging.info(f"ANALÄ°Z ðŸ§ : {game_name} verisi iÅŸleniyor...")

            # Gemini fonksiyonunu Ã§aÄŸÄ±r (API anahtarÄ±nÄ± korumak iÃ§in sÄ±ralÄ±)
            result = analyze_with_gemini(raw_data, game_name, send_alert)
            
            if result:
                save_json_to_s3(result, safe_name)
            else:
                logging.error(f"âŒ {game_name} analizi baÅŸarÄ±sÄ±z.")
            
            # API limitleri iÃ§in bekleme (son oyun hariÃ§)
            if i < len(fetched_data) - 1:
                delay = random.uniform(5, 12)
                logging.info(f"â³ Gemini rate limit korumasÄ± iÃ§in {delay:.1f} saniye bekleniyor...")
                time.sleep(delay)
        
        logging.info("âœ… TÃ¼m oyunlarÄ±n yama analizi baÅŸarÄ±yla tamamlandÄ±.")
        
    except Exception as e:
        logging.error(f"CRITICAL: Cron Job'da beklenmedik hata: {e}", exc_info=True)
        send_alert(f"CRITICAL: Cron Job'un tamamÄ± Ã§Ã¶ktÃ¼: {e}")
# -----------------------------------------------------------------
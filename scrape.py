# scrape.py
import os
import json
import time
from openai import OpenAI
from dotenv import load_dotenv
import requests
from bs4 import BeautifulSoup

# ğŸ” .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("âŒ .env dosyasÄ±nda OPENAI_API_KEY tanÄ±mlÄ± deÄŸil!")

client = OpenAI(api_key=OPENAI_API_KEY)

def fetch_valorant_patch_notes():
    """Valorant'in son yama sayfasÄ±ndan metni Ã§eker."""
    url = "https://playvalorant.com/en-us/news/game-updates/"
    try:
        print("ğŸŒ Valorant yama sayfasÄ± yÃ¼kleniyor...")
        res = requests.get(url, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')

        # TÃ¼m makale baÄŸlantÄ±larÄ±nÄ± bul
        links = soup.find_all("a", href=True)
        for link in links:
            href = link["href"]
            if "/en-us/news/game-updates/patch-notes" in href:
                full_url = "https://playvalorant.com" + href
                print(f"ğŸ“„ Yama notu bulundu: {full_url}")
                # Ä°Ã§eriÄŸi Ã§ek
                detail_res = requests.get(full_url, timeout=10)
                detail_soup = BeautifulSoup(detail_res.text, 'html.parser')
                # Ana iÃ§erik metnini al (basit yÃ¶ntem)
                content_div = detail_soup.find("div", class_="news-item-content")
                if content_div:
                    text = content_div.get_text(separator="\n", strip=True)
                    return text[:3000]  # Ä°lk 3000 karakter yeterli
        return None
    except Exception as e:
        print("âŒ Web scraping hatasÄ±:", e)
        return None

def analyze_with_openai(raw_text: str):
    """OpenAI ile metni analiz edip JSON dÃ¶ner."""
    prompt = f"""
    AÅŸaÄŸÄ±daki oyun yama notlarÄ±ndan sadece dengesizlik (nerf/buff), yeni iÃ§erik veya Ã¶nemli deÄŸiÅŸiklikleri Ã§Ä±kar.
    Sadece geÃ§erli JSON dÃ¶ndÃ¼r. HiÃ§bir aÃ§Ä±klama ekleme.
    Format:
    {{
      "game": "Valorant",
      "patch_version": "bilinmiyorsa 'unknown'",
      "date": "bilinmiyorsa 'unknown'",
      "changes": [
        {{
          "type": "nerf|buff|new|fix",
          "target": "karakter/silah",
          "ability": "yetenek (varsa)",
          "details": "aÃ§Ä±klama"
        }}
      ]
    }}

    Metin:
    {raw_text}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )
        content = response.choices[0].message.content.strip()

        # ```json ... ``` bloklarÄ±nÄ± temizle
        if content.startswith("```json"):
            content = content[7:-3].strip()
        elif content.startswith("```"):
            content = content[3:-3].strip()

        return json.loads(content)
    except Exception as e:
        print("âŒ OpenAI JSON hatasÄ±:", e)
        return None

def save_json(data, filename="valorant_latest.json"):
    os.makedirs("patches", exist_ok=True)
    path = os.path.join("patches", filename)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    print(f"âœ… JSON kaydedildi: {path}")

if __name__ == "__main__":
    print("ğŸš€ Otomatik yama analizi baÅŸlatÄ±lÄ±yor...")
    
    # 1. Web'den metin Ã§ek
    raw_text = fetch_valorant_patch_notes()
    if not raw_text:
        print("âš ï¸  Web'den veri alÄ±namadÄ±. Elle Ã¶rnek metin kullanÄ±lÄ±yor.")
        raw_text = """
        Jett's Updraft cooldown increased from 12s to 16s.
        Operator damage falloff reduced by 15%.
        New map 'Sunset' added.
        """

    print("\nğŸ“ Ham metin:\n", raw_text[:200], "...\n")

    # 2. OpenAI ile analiz et
    result = analyze_with_openai(raw_text)
    
    if result:
        save_json(result, "valorant_latest.json")
        print("\nğŸ§  OpenAI Sonucu:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        print("âŒ Analiz baÅŸarÄ±sÄ±z.")